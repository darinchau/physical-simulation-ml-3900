{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load import *\n",
    "from torch import Tensor, nn\n",
    "import torch\n",
    "from model_base import *\n",
    "from modules import *\n",
    "from anim import *\n",
    "import util\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "ROOT = \"./Datas/Week 8\"\n",
    "\n",
    "Q = 1.60217663e-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.3032e-10, dtype=torch.float64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = load_space_charge() * -Q\n",
    "ep = load_elec_potential()\n",
    "vg = load_vgs()\n",
    "poi = NormalizedPoissonMSE('cpu')\n",
    "poi(ep, sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This model does not need to be trained\n",
    "class PoissonJITRegressor(Model):\n",
    "    \"\"\"Use a first model to predict stuff, then use a second model to make them self consistent - aka satisfy the Poisson equation\"\"\"\n",
    "    def __init__(self, ep1: TrainedLinear, sc1: TrainedLinear):\n",
    "        # From the linearity plots, we only need to care about region 2 in practice for space charge\n",
    "        # and region 2, 5 for electric potential\n",
    "        self.ep1 = ep1\n",
    "        self.sc1 = sc1\n",
    "        \n",
    "    def forward(self, x):\n",
    "        num_data = int(x.shape[0])\n",
    "        # xep = x[:, :2193].reshape(-1, 129, 17)\n",
    "        # xsc = x[:, 2193:].reshape(-1, 129, 17)\n",
    "\n",
    "        naive_prediction = torch.cat([self.ep1(x), self.sc1(x)], dim = 1)\n",
    "\n",
    "        result = torch.zeros(num_data, 4386)\n",
    "        with torch.no_grad():\n",
    "            xep = self.ep1(x).cpu().numpy().reshape(-1, 129, 17)\n",
    "            xsc = self.sc1(x).cpu().numpy().reshape(-1, 129, 17)\n",
    "\n",
    "            poisson_loss = NormalizedPoissonRMSE('cpu')\n",
    "\n",
    "            # Nudge region 2, 5 of ep, region 2 of sc\n",
    "            # Refer to anim.py for region codes\n",
    "            # The mystery numbers are the number of parameters in different region\n",
    "            for i in range(num_data):\n",
    "                def reconstruct(x):\n",
    "                    ep_region_2 = x[:429].reshape(84 - 45, -1)\n",
    "                    ep_region_5 = x[429:663].reshape(84 - 45, -1)\n",
    "                    sc_region_2 = x[663:].reshape(84 - 45, -1)\n",
    "\n",
    "                    reconstructed_ep = xep[i]\n",
    "                    reconstructed_ep[45:84,:11] = ep_region_2\n",
    "                    reconstructed_ep[45:84,11:] = ep_region_5\n",
    "                    reconstructed_ep = torch.tensor(reconstructed_ep.reshape(1, 129, 17))\n",
    "\n",
    "                    reconstructed_sc = xsc[i]\n",
    "                    reconstructed_sc[45:84,:11] = sc_region_2\n",
    "                    reconstructed_sc = torch.tensor(reconstructed_sc.reshape(1, 129, 17))\n",
    "\n",
    "                    return reconstructed_ep, reconstructed_sc\n",
    "                \n",
    "                def minimize_me(x):\n",
    "                    reconstructed_ep, reconstructed_sc = reconstruct(x)\n",
    "                    mse = poisson_loss(reconstructed_ep, reconstructed_sc)\n",
    "                    return float(mse.item())\n",
    "                \n",
    "                ep_region_2 = xep[i,45:84,:11].reshape(-1)\n",
    "                ep_region_5 = xep[i,45:84,11:].reshape(-1)\n",
    "                sc_region_2 = xsc[i,45:84,:11].reshape(-1)\n",
    "\n",
    "                joined = np.concatenate([ep_region_2, ep_region_5, sc_region_2])\n",
    "                bounds = [(0, 1)] * 663 + [(-20, 20)] * 429\n",
    "                gradient_descent = minimize(minimize_me, x0 = joined, bounds = bounds)\n",
    "                grad_result = gradient_descent.x\n",
    "                new_ep, new_sc = reconstruct(grad_result)\n",
    "                result[i][:2193] = new_ep.reshape(-1)\n",
    "                result[i][2193:] = new_sc.reshape(-1)\n",
    "\n",
    "                print(f\"Frame {i}: Difference: {torch.mean(torch.abs(naive_prediction[i] - result[i]))}\", end = \"\")\n",
    "\n",
    "                poi = poisson_loss(new_ep, new_sc)\n",
    "                print(f\" Poisson loss: {poi}\")\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 0: Difference: 8.392442296667468e-10 Poisson loss: 0.00029653983074240386\n",
      "Frame 1: Difference: 7.474362795356626e-10 Poisson loss: 0.0003068466030526906\n",
      "Frame 2: Difference: 6.692951748377141e-10 Poisson loss: 0.00030469990451820195\n",
      "Frame 3: Difference: 8.76668682092685e-10 Poisson loss: 0.00031088184914551675\n",
      "Frame 4: Difference: 7.100762755563039e-10 Poisson loss: 0.00030516585684381425\n",
      "Frame 5: Difference: 8.663714745615891e-10 Poisson loss: 0.000309190945699811\n",
      "Frame 6: Difference: 5.641247469156951e-10 Poisson loss: 0.0003065404307562858\n",
      "Frame 7: Difference: 5.43778910788717e-10 Poisson loss: 0.00030361011158674955\n",
      "Frame 8: Difference: 6.455641576863513e-10 Poisson loss: 0.00030353700276464224\n",
      "Frame 9: Difference: 5.200215258405194e-10 Poisson loss: 0.0003132055571768433\n",
      "Frame 10: Difference: 2.6160310029332834e-10 Poisson loss: 0.0003089686797466129\n",
      "Frame 11: Difference: 2.922078412570528e-10 Poisson loss: 0.00031238346127793193\n",
      "Frame 12: Difference: 4.3150319428697514e-10 Poisson loss: 0.0003109706158284098\n",
      "Frame 13: Difference: 2.9909227872160216e-10 Poisson loss: 0.0003101081238128245\n",
      "Frame 14: Difference: 4.927594998704876e-10 Poisson loss: 0.0003116638108622283\n",
      "Frame 15: Difference: 4.366097205998898e-10 Poisson loss: 0.0003148819669149816\n",
      "Frame 16: Difference: 2.4905925783968996e-06 Poisson loss: 0.0003138838801532984\n",
      "Frame 17: Difference: 3.1025288080854807e-06 Poisson loss: 0.0003126967931166291\n",
      "Frame 18: Difference: 9.66341076491517e-07 Poisson loss: 0.00031270136241801083\n",
      "Frame 19: Difference: 1.0304642046321533e-06 Poisson loss: 0.00031209582812152803\n",
      "Frame 20: Difference: 0.0 Poisson loss: 0.00031726350425742567\n",
      "Frame 21: Difference: 2.6315590275771683e-06 Poisson loss: 0.0003141165361739695\n",
      "Frame 22: Difference: 1.1062323892474524e-06 Poisson loss: 0.00031627193675376475\n",
      "Frame 23: Difference: 9.291799756283581e-07 Poisson loss: 0.00031606206903234124\n",
      "Frame 24: Difference: 1.2246703136042925e-06 Poisson loss: 0.000312094169203192\n",
      "Frame 25: Difference: 1.235989998349396e-06 Poisson loss: 0.0003208585549145937\n",
      "Frame 26: Difference: 1.0161566166289049e-07 Poisson loss: 0.00031951640266925097\n",
      "Frame 27: Difference: 3.160292635584483e-06 Poisson loss: 0.0003141264314763248\n",
      "Frame 28: Difference: 3.403806431379053e-06 Poisson loss: 0.00031670654425397515\n",
      "Frame 29: Difference: 1.1698207345034461e-06 Poisson loss: 0.00031577597837895155\n",
      "Frame 30: Difference: 4.420109689817764e-06 Poisson loss: 0.0003156421007588506\n",
      "Frame 31: Difference: 2.9362279292399762e-06 Poisson loss: 0.0003145966329611838\n",
      "Frame 32: Difference: 7.612836725456873e-07 Poisson loss: 0.0003205644607078284\n",
      "Frame 33: Difference: 0.0 Poisson loss: 0.00032208385528065264\n",
      "Frame 34: Difference: 4.214238288113847e-06 Poisson loss: 0.0003245091938879341\n",
      "Frame 35: Difference: 0.0 Poisson loss: 0.00032227757037617266\n",
      "Frame 36: Difference: 1.60501954837855e-07 Poisson loss: 0.00032230993383564055\n",
      "Frame 37: Difference: 3.92000401916448e-06 Poisson loss: 0.00032096923678182065\n",
      "Frame 38: Difference: 2.6780683128890814e-06 Poisson loss: 0.00032446629484184086\n",
      "Frame 39: Difference: 3.3794628961913986e-07 Poisson loss: 0.00032257099519483745\n",
      "Frame 40: Difference: 1.915321035994566e-06 Poisson loss: 0.00032849167473614216\n",
      "Frame 41: Difference: 1.6686743720129016e-06 Poisson loss: 0.0003235747280996293\n",
      "Frame 42: Difference: 2.530580786697101e-06 Poisson loss: 0.0003266286221332848\n",
      "Frame 43: Difference: 2.214798996647005e-06 Poisson loss: 0.0003287302970420569\n",
      "Frame 44: Difference: 1.568846187183226e-06 Poisson loss: 0.0003248952270951122\n",
      "Frame 45: Difference: 2.3422628601110773e-06 Poisson loss: 0.0003311009204480797\n",
      "Frame 46: Difference: 6.118959277046088e-07 Poisson loss: 0.0003252363239880651\n",
      "Frame 47: Difference: 1.2662292192544555e-06 Poisson loss: 0.0003313593042548746\n",
      "Frame 48: Difference: 1.3883635574529762e-06 Poisson loss: 0.0003350006591062993\n",
      "Frame 49: Difference: 2.8015510906698182e-06 Poisson loss: 0.00033479658304713666\n",
      "Frame 50: Difference: 2.9235029614937957e-06 Poisson loss: 0.0003410196222830564\n",
      "Frame 51: Difference: 2.80570202448871e-06 Poisson loss: 0.00033888136385940015\n",
      "Frame 52: Difference: 3.862593985104468e-06 Poisson loss: 0.00034312132629565895\n",
      "Frame 53: Difference: 6.469203981396277e-07 Poisson loss: 0.00034357589902356267\n",
      "Frame 54: Difference: 1.3714455917579471e-06 Poisson loss: 0.00035229994682595134\n",
      "Frame 55: Difference: 1.553366473672213e-06 Poisson loss: 0.00034603517269715667\n",
      "Frame 56: Difference: 1.0250026889480068e-06 Poisson loss: 0.0003475909761618823\n",
      "Frame 57: Difference: 4.14112309954362e-06 Poisson loss: 0.0003455519618000835\n",
      "Frame 58: Difference: 4.1754665289772674e-06 Poisson loss: 0.00035293257678858936\n",
      "Frame 59: Difference: 0.0 Poisson loss: 0.00034557830076664686\n",
      "Frame 60: Difference: 1.6619073903711978e-06 Poisson loss: 0.00034856662387028337\n",
      "Frame 61: Difference: 6.113218660175335e-07 Poisson loss: 0.00035208341432735324\n",
      "Frame 62: Difference: 6.648604994552443e-06 Poisson loss: 0.000350101210642606\n",
      "Frame 63: Difference: 1.6252226942015113e-06 Poisson loss: 0.0003527193912304938\n",
      "Frame 64: Difference: 3.4114232221327256e-06 Poisson loss: 0.00035369425313547254\n",
      "Frame 65: Difference: 2.0689551547548035e-06 Poisson loss: 0.0003530933754518628\n",
      "Frame 66: Difference: 3.086966898990795e-06 Poisson loss: 0.00035761986509896815\n",
      "Frame 67: Difference: 5.773042630607961e-07 Poisson loss: 0.0003482744505163282\n",
      "Frame 68: Difference: 1.6673837990310858e-06 Poisson loss: 0.00035112950718030334\n",
      "Frame 69: Difference: 3.4686722756305244e-06 Poisson loss: 0.00035290076630190015\n",
      "Frame 70: Difference: 2.6234627057419857e-06 Poisson loss: 0.00035556749207898974\n",
      "Frame 71: Difference: 1.9163317119819112e-06 Poisson loss: 0.0003610601706895977\n",
      "Frame 72: Difference: 1.189564386550046e-06 Poisson loss: 0.00036820999230258167\n",
      "Frame 73: Difference: 0.0 Poisson loss: 0.0003681679954752326\n",
      "Frame 74: Difference: 0.0 Poisson loss: 0.00037036111461929977\n",
      "Frame 75: Difference: 4.462758170120651e-06 Poisson loss: 0.00037434001569636166\n",
      "Frame 76: Difference: 6.049952503417444e-07 Poisson loss: 0.000374335766537115\n",
      "Frame 77: Difference: 4.076443929079687e-06 Poisson loss: 0.000365241285180673\n",
      "Frame 78: Difference: 0.0 Poisson loss: 0.00037083119968883693\n",
      "Frame 79: Difference: 0.0 Poisson loss: 0.0003818538098130375\n",
      "Frame 80: Difference: 2.882226908695884e-06 Poisson loss: 0.00037972014979459345\n",
      "Frame 81: Difference: 3.824778559646802e-06 Poisson loss: 0.0003799544065259397\n",
      "Frame 82: Difference: 1.4296849712991389e-06 Poisson loss: 0.0003870733780786395\n",
      "Frame 83: Difference: 1.1949467193517194e-07 Poisson loss: 0.000382714148145169\n",
      "Frame 84: Difference: 5.6843300626496784e-06 Poisson loss: 0.00037699969834648073\n",
      "Frame 85: Difference: 5.626939582725754e-06 Poisson loss: 0.00038402952486649156\n",
      "Frame 86: Difference: 5.950030299572973e-06 Poisson loss: 0.0003810097405221313\n",
      "Frame 87: Difference: 3.35667391482275e-06 Poisson loss: 0.0003824657469522208\n",
      "Frame 88: Difference: 0.0 Poisson loss: 0.0003867731138598174\n",
      "Frame 89: Difference: 3.942166586057283e-06 Poisson loss: 0.0003915817360393703\n",
      "Frame 90: Difference: 5.361272087611724e-06 Poisson loss: 0.0003875381371472031\n",
      "Frame 91: Difference: 4.615098532667616e-06 Poisson loss: 0.00039107847260311246\n",
      "Frame 92: Difference: 1.202862904392532e-06 Poisson loss: 0.00039710113196633756\n",
      "Frame 93: Difference: 0.0 Poisson loss: 0.00038799524190835655\n",
      "Frame 94: Difference: 1.592566604813328e-06 Poisson loss: 0.0003987983800470829\n",
      "Frame 95: Difference: 5.7000506785698235e-06 Poisson loss: 0.00038683167076669633\n",
      "Frame 96: Difference: 4.916357283946127e-06 Poisson loss: 0.00039918776019476354\n",
      "Frame 97: Difference: 1.0452127980897785e-06 Poisson loss: 0.0004062176449224353\n",
      "Frame 98: Difference: 1.0349747299187584e-06 Poisson loss: 0.0004099416546523571\n",
      "Frame 99: Difference: 4.421998255565995e-06 Poisson loss: 0.00039762796950526536\n",
      "Frame 100: Difference: 1.5211077197818668e-06 Poisson loss: 0.000407667102990672\n"
     ]
    }
   ],
   "source": [
    "x = vg[:30]\n",
    "epy = ep[:30]\n",
    "scy = sc[:30]\n",
    "ep_linear = TrainedLinear(1, 2193, algorithm='linear').fit(x, epy.reshape(-1, 2193))\n",
    "sc_linear = TrainedLinear(1, 2193, algorithm='linear').fit(x, scy.reshape(-1, 2193))\n",
    "model = PoissonJITRegressor(ep_linear, sc_linear)\n",
    "ypred = model(vg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Darin\\Documents\\Repository\\physical-simulation-ml-3900\\anim.py:423: RuntimeWarning: divide by zero encountered in log10\n",
      "  err_log_10 = np.log10(error)\n",
      "c:\\Users\\Darin\\Documents\\Repository\\physical-simulation-ml-3900\\anim.py:423: RuntimeWarning: divide by zero encountered in log10\n",
      "  err_log_10 = np.log10(error)\n"
     ]
    }
   ],
   "source": [
    "from anim import make_anim\n",
    "\n",
    "ypred_ep = ypred[:, :2193].reshape(-1, 129, 17)\n",
    "ypred_sc = ypred[:, 2193:].reshape(-1, 129, 17)\n",
    "\n",
    "make_anim(ypred_ep, ep, \"ep_jit1.gif\", \"Electric potential first 30\")\n",
    "make_anim(ypred_sc, sc, \"sc_jit1.gif\", \"Space charge first 30\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
